<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>augmented reality | Srinidhi Hegde</title>
    <link>https://srihegde.github.io/tag/augmented-reality/</link>
      <atom:link href="https://srihegde.github.io/tag/augmented-reality/index.xml" rel="self" type="application/rss+xml" />
    <description>augmented reality</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Some rights reserved Â©2024. Srinidhi Hegde</copyright><lastBuildDate>Fri, 01 Mar 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://srihegde.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>augmented reality</title>
      <link>https://srihegde.github.io/tag/augmented-reality/</link>
    </image>
    
    <item>
      <title>SmartOverlays</title>
      <link>https://srihegde.github.io/project/smartov/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/project/smartov/</guid>
      <description>&lt;p&gt;A novel method for the placement of labels corresponding to objects of interest in images/videos/live feeds that is non-intrusive, relevant and temporally coherent. We employ different techniques ranging from search space optimization to visual saliency based neural network framework.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Draw In Air</title>
      <link>https://srihegde.github.io/project/drawinair/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/project/drawinair/</guid>
      <description>&lt;p&gt;Hand gesture classification through fingertip coordinate regression in a temporal model for touch-less interactions in AR. We highlight how a model, that is separately trained to regress fingertip in conjunction with a classifier trained on limited classification data, would perform better over end-to-end models. We also propose a dataset of 10 egocentric pointing gestures designed for AR applications for testing our model.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
