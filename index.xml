<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Srinidhi Hegde</title>
    <link>https://srihegde.github.io/</link>
      <atom:link href="https://srihegde.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Srinidhi Hegde</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Some rights reserved ©2023. Srinidhi Hegde</copyright><lastBuildDate>Mon, 17 Jul 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://srihegde.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Srinidhi Hegde</title>
      <link>https://srihegde.github.io/</link>
    </image>
    
    <item>
      <title>Diffusion Models Beat GANs on Image Classification</title>
      <link>https://srihegde.github.io/publication/arxiv2023/</link>
      <pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/publication/arxiv2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Kaleidoscope</title>
      <link>https://srihegde.github.io/post/art_album/</link>
      <pubDate>Fri, 08 Jul 2022 19:04:57 -0500</pubDate>
      <guid>https://srihegde.github.io/post/art_album/</guid>
      <description>&lt;p&gt;In case you find art and geometry fascinating, &lt;a href=&#34;https://photos.app.goo.gl/TAywH8mpeh2vMkcYA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; is my collection of some snaps that held my gaze.&lt;/p&gt;
&lt;p&gt;(Subject to Copyright © Srinidhi Hegde 2022.)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The &#34;Bi&#34;-Cycle Saga</title>
      <link>https://srihegde.github.io/post/bikesaga/</link>
      <pubDate>Sun, 02 Jan 2022 19:04:57 -0500</pubDate>
      <guid>https://srihegde.github.io/post/bikesaga/</guid>
      <description>&lt;p&gt;Peering out of the window on a lazy Sunday afternoon I noticed something peculiar about the house across the street. A break of 3000 odd house numbers between my neighbor and my house didn’t add up to me. My neighborhood was a tiny enclosure amidst the crotched bustling highways of Maryland. How in the world could this small patch of land fit all these houses? Revelations and tragedy always strike with an element of surprise. But what is worse? Both struck me simultaneously as I realized that these unaccounted houses were the progeny of my amnesic memory which threw up an incorrect house number for my new residence. However, I don’t blame myself for this. This episode happened while I was settling in a foreign land having stuck to a single house number all my life.&lt;/p&gt;
&lt;p&gt;But wait, why is this a tragedy, you ask? Well, this was the incorrect address that I typed in while ordering my brand new bicycle (or bike, as Americans call it) from Walmart. Regaining my composure, I first checked if this incorrect address actually existed, so that I can just collect it from there. But remember, it was a tiny neighborhood and I had directed my package to a house that was 3000 houses away and literally nowhere on earth. So I did the next natural thing that a panic-struck customer does. Calling the Walmart support center. A kind woman answered my call and as I poured out my vexation she looked up my order details. After several rounds of information exchange, we figured out that we could not cancel the order as it was an expensive purchase and it was on its way to delivery. “Can the delivery service at least deliver my bike to the updated location?”, I asked. After a doubtful pause and a quick consultation with her supervisor, she announced, “Yes, you can expect the package within 2 days”. And with that, I gave a sigh of relief. But little did I know how far I was from the relief!&lt;/p&gt;
&lt;p&gt;Three days had passed and there was still no sign of my bike and my paranoia was ballooning. Being a faithful paranoid customer, I dialed up the support center again. This time I heard a different male voice from the other side. And this meant I had to revisit my predicament and also the solution which we had arrived at. After hearing my account, the support staff pondered for a while, verified the purchase records, and nonchalantly declared that my order was canceled and the refund was initiated. After hearing this unpleasant news, I hung up the call and immediately rushed to reorder the same bike. But the product had run out of stock! Having surveyed gazillion bikes online, gauging their tire size, off-road riding, price, … (replace with any filter you can think of, yes including gender), I had lost it all. With a heavy heart, I settled for the next best bike on my surveyed bike list. And I promptly ordered this bike online, of course, with the right address this time.&lt;/p&gt;
&lt;p&gt;The next morning as I got ready to leave for my early morning classes in the university, I saw a huge tattered cardboard box blocking my house entrance. And what’s more? The box was addressed for me and the first thing that clicked me was the new bike that I ordered the day before. Boy was I impressed by Walmart’s supersonic delivery. Since I was getting late for my lecture, controlling my excitement, I shoved the hefty package inside the house and rushed for the classes. To be honest, I could not concentrate on the lecture that day. Biking to campus, swishing past the pedestrians, minting precious time for myself, and thoughts alike kept feeding the butterflies in my stomach. Yes, I know I didn’t care much about its features, for the bike was the cheapest and the most basic one, probably in the entire campus, that could just take me places. In short, I was fixated on the tattered box in my verandah.&lt;/p&gt;
&lt;p&gt;As the class ended that day, it was probably one of the fastest walks (actually interspersed bursts of sprints) that I had to my home. I unlocked the front door of my house, rushed towards the box picking the nearby scissors. Snip! Snip! I effortlessly tore open the already tattered box. But what do I discover here? This was the bike that I had ordered before ordering my replacement bike that was inferior to my first bike. Did you read too many bikes? Don’t worry. Let us call the first bike (that was canceled) the red bike and the second bike (the replacement) the blue bike and I had received the red bike in the package. Well, this was a confusing situation for me. To aggravate the matters, I woke up to another package the next day, waiting for me. I carefully went over the same exercise of tearing-up-the-tattered-cardboard. What do I find here? Yes, you guessed it right. It was the blue bike (yikes! I have 2 bikes!). That was the moment I was lost somewhere amidst the confusion of joy, awe, anxiety(over returning and refund process), and, anger (directed at Walmart and partly to myself).&lt;/p&gt;
&lt;p&gt;After several unsuccessful attempts to bring me to my senses, it took me three weeks to accept what had happened. I had neither received the refund for the red bike (which was anticipated in 8-10 business days) nor did I hear anything from Walmart till then. And I was the unexpected owner of two bikes and I was presented with the choice of red cycle versus the blue cycle. Although it sounds like the iconic red and blue pills of Keanu Reaves’ Matrix. But making a decision here was not that hard. I decided to keep the red one but what to do with the blue bike? Luckily for me, one of my housemates did not have a bike and it took me a little bit of convincing to sell my bike to him (how I marketed my product could be a topic for a separate blog post).&lt;/p&gt;
&lt;p&gt;Now, if you are wondering if this was my “happily ever after” moment, then hold your horses. After a week, almost a month had passed since the refund for my red bike was initiated. It seems like the stars aligned well that day and I got my refund. So now I had two bikes one of which was free! Finally, I was relieved. But in my hindsight, I had a sinister feeling that something was not right. Moreover, one of my friends, after hearing my case, subtly prompted that this seems illegal and I could be up for some trouble.  Firing up my researcher instincts, I scoured through the internet to verify if I am the unlucky one. Well to my surprise, not one or two but hundreds of cases like this crop up every year due to logistical goof-ups. To make the matters worse, I also read that some state jurisdictions consider this as theft and a 6th-degree felony leading up to a year’s prison term! Instantly, my relief switched to paranoia. Do I have to return my bike? My favorite red bike? Or even worse, will I be incarcerated? To remedy this situation, I dialed the Walmart service center once again and apologetically explained myself to the support staff. After a momentary pause, which seemed like eons to me, I heard the three golden words - “Just keep it!”. No questions asked. Period. By this time, I was so used to my paranoia that I breathed a sigh of relief anyway. I finally owned a freebie bike legally. How cool is that?&lt;/p&gt;
&lt;p&gt;Even now, just to give my creativity some rest, I recycle this story as icebreakers in conversations during parties, dinners, and even in classrooms! (What’s worse, I can refer to this blog from now on.) My audience generally compliments my honesty and some are even surprised that I called the support center to clarify. But little do they know that this should be credited to my guilt and paranoia. Looking back at this whole episode, I do and don’t blame Walmart for this episode. But I can’t complain either. On the flip side, I always cherish how I came so close to stealing a bike and getting away with it!&lt;/p&gt;
&lt;p&gt;If you have made it so far, I thank you for your awesomeness.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rethinking Common Assumptions to Mitigate Racial Bias in Face Recognition Datasets</title>
      <link>https://srihegde.github.io/publication/iccv2021/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/publication/iccv2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cross-Domain Multi-task Learning for Object Detection and Saliency Estimation</title>
      <link>https://srihegde.github.io/publication/cvprw2021/</link>
      <pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/publication/cvprw2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Empirical Study of Iterative Knowledge Distillation for Neural Network Compression</title>
      <link>https://srihegde.github.io/publication/esann2020/</link>
      <pubDate>Fri, 02 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/publication/esann2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Variational Student: Learning Compact and Sparser Networks in Knowledge Distillation Framework</title>
      <link>https://srihegde.github.io/publication/icassp2020/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/publication/icassp2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SmartOverlays: A Visual Saliency Driven Label Placement for Intelligent Human-Computer Interfaces</title>
      <link>https://srihegde.github.io/publication/wacv2020/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/publication/wacv2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep Neural Network Compression</title>
      <link>https://srihegde.github.io/project/nncomp/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/project/nncomp/</guid>
      <description>&lt;p&gt;Compressing the memory-intensive DNN models with a minimal compromise in model accuracy using variational methods and knowledge distillation. Another part of projects involves proposing theoretical guarantees on the knowledge distillation models for efficient neural architecture search.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reverse VooDoo</title>
      <link>https://srihegde.github.io/arxiv_projects/animation/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/arxiv_projects/animation/</guid>
      <description>&lt;p&gt;Automating the animation through learning and transferring motion cues from the real RGB-D videos to virtual 3D meshes. We use graph based structure correspondences to map the motion between the two 3D entities such as point cloud and 3D meshes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SmartOverlays</title>
      <link>https://srihegde.github.io/project/smartov/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/project/smartov/</guid>
      <description>&lt;p&gt;A novel method for the placement of labels corresponding to objects of interest in images/videos/live feeds that is non-intrusive, relevant and temporally coherent. We employ different techniques ranging from search space optimization to visual saliency based neural network framework.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DrawInAir: A Lightweight Gestural Interface Based on Fingertip Regression</title>
      <link>https://srihegde.github.io/publication/eccv2018/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/publication/eccv2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Where To Place: A Real-Time Visual Saliency Based Label Placement for Augmented Reality Applications</title>
      <link>https://srihegde.github.io/publication/icip2018/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/publication/icip2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Draw In Air</title>
      <link>https://srihegde.github.io/project/drawinair/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/project/drawinair/</guid>
      <description>&lt;p&gt;Hand gesture classification through fingertip coordinate regression in a temporal model for touch-less interactions in AR. We highlight how a model, that is separately trained to regress fingertip in conjunction with a classifier trained on limited classification data, would perform better over end-to-end models. We also propose a dataset of 10 egocentric pointing gestures designed for AR applications for testing our model.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robust 3D Reconstruction of Indoor Scenes using Deep Learning</title>
      <link>https://srihegde.github.io/project/btp/</link>
      <pubDate>Mon, 01 May 2017 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/project/btp/</guid>
      <description>&lt;p&gt;Employing CNNs for an end-to-end reconstruction of the indoor scenes through camera relocalization, through PoseNet, and depth estimation, through multi-scale fully convolutional network, from a single RGB image during inference and registering the 3D reconstructed patches through iterative closest point algorithm. A portion of the dataset collected during the project is also released.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GestAR: Real Time Gesture Interaction for AR with Egocentric View</title>
      <link>https://srihegde.github.io/publication/ismar2016/</link>
      <pubDate>Wed, 01 Jun 2016 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/publication/ismar2016/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Distributed Fault Tolerant Multi-Robot Area Coverage Under Limited Communication Ranges</title>
      <link>https://srihegde.github.io/project/mas/</link>
      <pubDate>Sun, 01 May 2016 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/project/mas/</guid>
      <description>&lt;p&gt;This work develops a distributed fault tolerant area coverage algorithm, resulting in quick detection of the faulty agent under limited communication constraints and redistributes the area without conflicts.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Modelling Vegetation with L-Systems Using an Image</title>
      <link>https://srihegde.github.io/project/lsys/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/project/lsys/</guid>
      <description>&lt;p&gt;Realistic models of vegetations are very essential piece of immersive virtual environment simulations. We develop a novel technique to convert a single captured image of a vegetation to a 3D model using L-Systems, a context-free grammar that we adapt to procedurally model vegetation. We also propose a pipeline that is semi-automated with manual interventions for accurate identification of tree branches and trunk.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vision Based Outdoor Localization</title>
      <link>https://srihegde.github.io/arxiv_projects/visloc/</link>
      <pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/arxiv_projects/visloc/</guid>
      <description>&lt;p&gt;Estimating GPS location of a single RGB image of outdoor environment by, firstly, GPS coordinate retrieval from image classification and secondly, fine tuning the location estimate using structure from motion and and position triangulation. This application was interfaced by an Android mobile application.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sketch23D</title>
      <link>https://srihegde.github.io/project/sketch23d/</link>
      <pubDate>Tue, 01 Dec 2015 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/project/sketch23d/</guid>
      <description>&lt;p&gt;We present an interactive sketching interface for quick and easy designing of freeform 3D models using OpenGL and CGAL libraries in C++. The mesh construction employs Shewchuk&amp;rsquo;s algorithm (which is based on Delaunay Triangulation). The freehand interaction and mesh construction is perfomed in real-time.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Virtual Campus Project</title>
      <link>https://srihegde.github.io/project/vcp/</link>
      <pubDate>Tue, 01 Dec 2015 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/project/vcp/</guid>
      <description>&lt;p&gt;This project proposes to build a virtual smart campus infrastructure. A 3D interactive and immersive virtual/mixed reality environment will be designed to support geospatial services including smart navigation and telepresence. Two key aspects of the system are 3D modeling and rendering.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Creating Cloud of Local Servers</title>
      <link>https://srihegde.github.io/arxiv_projects/vcloud/vcloud/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/arxiv_projects/vcloud/vcloud/</guid>
      <description>&lt;p&gt;Developed a web application, that takes input from the user about his/her preferences about the specification of the machine which include - operating system, main memory space, disk(storage) space, number of cores. Then we return the IP of the machine (Virtual Machine) assigned according to the mentioned preferences, for a particular amount of time. We use KVM for VM management.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Events Archive</title>
      <link>https://srihegde.github.io/news/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/news/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;17th July 2023&lt;/strong&gt;: Our work &amp;ldquo;Diffusion Models Beat GANs on Image Classification&amp;rdquo; published on Arxiv. Check it out &lt;a href=&#34;https://arxiv.org/pdf/2307.08702.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;21st May 2023&lt;/strong&gt;: Graduated from UMD with masters in Computer Science!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;18th Oct 2021&lt;/strong&gt;: My co-authored work &amp;ldquo;Rethinking Common Assumptions to Mitigate Racial Bias in Face Recognition Datasets&amp;rdquo;  won the best paper running up award at ICCV (HTCV &amp;lsquo;21)! Congrats to all the co-authors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;1st Aug 2021&lt;/strong&gt;: My co-authored work &amp;ldquo;Rethinking Common Assumptions to Mitigate Racial Bias in Face Recognition Datasets&amp;rdquo; accepted at ICCV (HTCV &amp;lsquo;21) as a oral paper. My first publication as a UMD student!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;25th May 2021&lt;/strong&gt;: I have started my grad school at University of Maryland, College Park.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;13th Apr 2021&lt;/strong&gt;: My co-authored work &amp;ldquo;Cross-Domain Multi-task Learning for Object Detection and Saliency Estimation&amp;rdquo; accepted at CVPR (CLVISION &amp;lsquo;21) as a poster.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;14th Feb 2021&lt;/strong&gt;: Received TCS Citation Award for the second time for outstanding contributions to the organization through publications.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;20th July 2020&lt;/strong&gt;: Invited as a reviewer for IEEE Transactions on Circuits and Systems for Video Technology (TCSVT, impact factor: 3.599). My first journal reviewing experience!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;21st Mar 2020&lt;/strong&gt;: TreasAR Hunt - an AR based treasure hunt - organized for Re.Fresh 2020 at TCS Innovation Labs New Delhi. The &lt;a href=&#34;https://github.com/srihegde/TreasAR-Hunt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;source code&lt;/a&gt; is now available. Check it out!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;24th Jan 2020&lt;/strong&gt;: Variational Student: Our work on neural network compression through sparsification in Knowledge Distillation framework got accepted as an &lt;strong&gt;&amp;ldquo;oral presentation&amp;rdquo;&lt;/strong&gt; at &lt;a href=&#34;https://2020.ieeeicassp.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICASSP 2020&lt;/a&gt; to be held at Barcelona, Spain.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;24th Jan 2020&lt;/strong&gt;: IKD: Our work on empirical analysis of iterative knowledge distillation methods got accepted at &lt;a href=&#34;https://www.esann.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESANN 2020&lt;/a&gt; to be held at Bruges, Belgium.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;17th Sep 2019&lt;/strong&gt;: SmartOverlays: Our work on situated visualization in AR and video application got accepted at &lt;a href=&#34;http://wacv20.wacv.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WACV 2020&lt;/a&gt; to be held at Aspen, Colorado.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;6th Jul 2019&lt;/strong&gt;: Attended EEML Summer School 2019, Bucharest, Romania. My experience was &lt;a href=&#34;https://www.linkedin.com/posts/srihegde_eeml2019-tcsresearch-bayesianlearning-activity-6553721146418790400-5fV8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;awesome&lt;/a&gt;!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;15th March 2019&lt;/strong&gt;: Selected for &lt;a href=&#34;https://www.eeml.eu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EEML Summer School 2019&lt;/a&gt;. Travelling to Bucharest, Romania in July.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;21st Jan 2019&lt;/strong&gt;: TCS-PanIIT Conclave 2019- &lt;a href=&#34;https://www.linkedin.com/posts/srihegde_hackathon-iit-paniit-activity-6495213414233796608-GlZh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hackathon Update&lt;/a&gt;: Mentored teams finished at 3rd and 4th positions in the event. Kudos to the team members!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;14th Jan 2019&lt;/strong&gt;: Selected as mentor for PanIIT Hackathon at &lt;a href=&#34;https://www.tcs.com/paniit-conclave-2019&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TCS-PanIIT Conclave 2019&lt;/a&gt; organized by TCS and IIT Delhi.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Network Traffic Generator and Packet Analyzer</title>
      <link>https://srihegde.github.io/arxiv_projects/netpack/netpack/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://srihegde.github.io/arxiv_projects/netpack/netpack/</guid>
      <description>&lt;p&gt;In this project we developed an IPv4 packet generator to simulate any network traffic the user wants. We interfaced this through a web application to provide user the provision for customizing source and destination IPs and ports,the protocol to be used and amount of that data each of the packets carry. We analyzed the most used protocols and identifying clogging points in network.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
